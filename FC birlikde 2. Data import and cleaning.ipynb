{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title \n",
    "## 2. Data import and cleaning\n",
    "\n",
    "* Data import and basic cleaning\n",
    "    * Hate Map Data from SPLC\n",
    "    * Table 13 from FBI Hate Crime Data\n",
    "    * Table 11 from FBI Hate Crime Data\n",
    "* Combining tables\n",
    "\n",
    "\n",
    "### Hate Map Data from SPLC\n",
    "\n",
    "The Hate Map data is all from the [SPLC](https://www.splcenter.org/hate-map). They have data from, I believe, 2000 until 2017 available. It shows the names of hate groups, their hate type, and their locations across the united states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, getting the excel file which has each year's data in a different sheet\n",
    "\n",
    "xl_file = \"/Users/gemma/Documents/data science/splc-hate-groups-previous-years.xls\"\n",
    "\n",
    "# reading it in as a dict to then make the dataframe from that dict\n",
    "sheets_dict = pd.read_excel(xl_file, sheet_name=None)\n",
    "\n",
    "hatemaps = pd.DataFrame()\n",
    "for name, sheet in sheets_dict.items():\n",
    "    sheet['Year'] = int(name)\n",
    "    # some of the col names arent standardized the same across years - correcting that here\n",
    "    if 'City/Region' in sheet.columns.values:\n",
    "        sheet.rename(columns={'City/Region':'City'}, inplace=True)\n",
    "    if 'Group name' in sheet.columns.values:\n",
    "        sheet.rename(columns={'Group name':'Group Name'}, inplace=True) \n",
    "       \n",
    "    hatemaps = hatemaps.append(sheet, sort=False)\n",
    "\n",
    "hatemaps.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Hate Type</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Christian Dixie Knights of the Ku Klu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AL</td>\n",
       "      <td>Ku Klux Klan</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Confederate Knights of the Ku Klux Klan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TN</td>\n",
       "      <td>Ku Klux Klan</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Church of the American Christian Knights</td>\n",
       "      <td>Moselle</td>\n",
       "      <td>MS</td>\n",
       "      <td>Ku Klux Klan</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Church of the National Knights of the Ku Klux ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KY</td>\n",
       "      <td>Ku Klux Klan</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Church of the National Knights of the Ku Klux ...</td>\n",
       "      <td>Panama</td>\n",
       "      <td>NY</td>\n",
       "      <td>Ku Klux Klan</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Group Name     City State  \\\n",
       "0  American Christian Dixie Knights of the Ku Klu...      NaN    AL   \n",
       "1   American Confederate Knights of the Ku Klux Klan      NaN    TN   \n",
       "2           Church of the American Christian Knights  Moselle    MS   \n",
       "3  Church of the National Knights of the Ku Klux ...      NaN    KY   \n",
       "4  Church of the National Knights of the Ku Klux ...   Panama    NY   \n",
       "\n",
       "      Hate Type  Year  Unnamed: 4 Unnamed: 5  \n",
       "0  Ku Klux Klan  2017         NaN        NaN  \n",
       "1  Ku Klux Klan  2017         NaN        NaN  \n",
       "2  Ku Klux Klan  2017         NaN        NaN  \n",
       "3  Ku Klux Klan  2017         NaN        NaN  \n",
       "4  Ku Klux Klan  2017         NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatemaps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "2000     0\n",
       "2001     0\n",
       "2002     0\n",
       "2003     0\n",
       "2004     0\n",
       "2005     0\n",
       "2006     0\n",
       "2007    90\n",
       "2008     0\n",
       "2009     0\n",
       "Name: Unnamed: 4, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the last two columns - 5 contains only NaN, what about 4? \n",
    "hatemaps.sort_values(by='Unnamed: 4', ascending=False)\n",
    "\n",
    "hatemaps.groupby(['Year'])['Unnamed: 4'].count().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since columns \"Unnamed 4\" and \"5\" contain either no data (5) or data only for 2007 (4)...\n",
    "hatemaps.drop(['Unnamed: 5', 'Unnamed: 4'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006,\n",
       "       2005, 2004])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatemaps = hatemaps.query('(Year > 2003) & (Year < 2017)')\n",
    "\n",
    "# double checking it worked\n",
    "hatemaps['Year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Ku Klux Klan', 'Neo-Nazi', 'White Nationalist',\n",
       "       'Racist Skinhead', 'Christian Identity', 'Black Nationalist',\n",
       "       'Neo-Confederate', 'Anti-LGBT', 'Anti-Muslim', 'Anti-Immigration',\n",
       "       'General Hate', 'Holocaust Denial', 'Racist Music',\n",
       "       'Radical Traditional Catholicism', 'Anti-Immigrant',\n",
       "       'Ku Klux Klan', 'GH_Anti-Immigration', 'GH_Anti-LGBT',\n",
       "       'GH_Anti-Muslim', 'GH_Holocaust_Denial', 'GH_Other',\n",
       "       'GH_Racial_Music', 'GH_Radical_Trad_Catholilicism', 'ANTI-LGBT',\n",
       "       'Other', 'Radical Traditional Catholilic', 'GH_Anti-Gay',\n",
       "       'Anti-Gay', 'Radical Traditionalist Catholic', 'General/Anti-Gay',\n",
       "       'General/Anti-Immigrant', 'General/Holocaust Denial',\n",
       "       'General/Other', 'General/Racist Music',\n",
       "       'General/Radical Catholic'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at some of the string data that could be inconsistent...\n",
    "\n",
    "hatemaps['Hate Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing a dict of the Hate Group types that are not consistent\n",
    "\n",
    "corrects = {' Ku Klux Klan': 'Ku Klux Klan','GH_Anti-Muslim' :'Anti-Muslim' , }\n",
    "\n",
    "corrects.update(corrects.fromkeys(['GH_Anti-LGBT',\n",
    "                                  'ANTI-LGBT','Anti-Gay','GH_Anti-Gay',\n",
    "                                  'General/Anti-Gay'],'Anti-LGBT'))\n",
    "\n",
    "corrects.update(corrects.fromkeys(['GH_Radical_Trad_Catholilicism', 'Radical Traditional Catholicism ',\n",
    "                                  'Radical Traditional Catholilic',\n",
    "                                 'Radical Traditionalist Catholic', \n",
    "                              'General/Radical Catholic'],'Radical Traditional Catholicism'))\n",
    "\n",
    "corrects.update(corrects.fromkeys(['Anti-Immigration','GH_Anti-Immigration', \n",
    "                               'General/Anti-Immigrant'],'Anti-Immigrant'))\n",
    "\n",
    "corrects.update(corrects.fromkeys(['General Hate','GH_Other', \n",
    "                                'Other'],'General/Other'))\n",
    "\n",
    "corrects.update(corrects.fromkeys(['GH_Holocaust_Denial', \n",
    "                               'General/Holocaust Denial'],'Holocaust Denial'))\n",
    "\n",
    "corrects.update(corrects.fromkeys(['General/Racist Music','Racist Music', \n",
    "                                'GH_Racial_Music', 'Hate Music'],'Racist / Hate Music'))\n",
    "\n",
    "# a little function\n",
    "def check_and_replace(value):\n",
    "    if value in corrects:\n",
    "        return corrects[value]\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the hate types consistent\n",
    "\n",
    "hatemaps['Hate Type'] = hatemaps['Hate Type'].apply(check_and_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the names of the hate groups are also a mess... let's clean them up\n",
    "\n",
    "# dropping punctuation / strange characters\n",
    "import re\n",
    "def cleanup(text):\n",
    "    # get rid of anything that is not a letter\n",
    "    text = re.sub(r'[ˆ0-9]+[^\\s]+[\\W]+\\*+','',text)   \n",
    "    text = re.sub(r'\\*+', '', text) # get rid of *s\n",
    "    text = re.sub(r'[\\\\x]+', '', text) # get rid of \\xs\n",
    "    text = re.sub(r'\\\\+', '', text) # get rid of \\s\n",
    "    #text = re.sub(r'\"', '', text) # get rid of \"s\n",
    "    text = ' '.join(text.split('  ')) # get rid of extra spaces\n",
    "    text = text.lower()     # make it all lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatemaps['Group Name'] = hatemaps['Group Name'].apply(cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hate Crime Data from FBI \n",
    "\n",
    "FBI data from [UCR](https://www.fbi.gov/services/cjis/ucr/publications#Hate-Crime%20Statistics). (Years prior to 2004 are available as pdfs only.)\n",
    "\n",
    "While there are 14 different tables with information for each year, I'm going to focus on the following two tables from each year:\n",
    "\n",
    "* Table 11: Offenses: Offense Type by Participating State\n",
    "* Table 13: Hate Crime Incidents, by Bias Motivation, by State, Agency Type, and Number of Quarters Reported\n",
    "\n",
    "Year 2012 also has a Table 13 Addendum, which has data that was not included in the rest of the tables because it was submit late to the FBI by the agencies.\n",
    "\n",
    "Also, Table 13 from 2004 and 2005 is in a different format. So we will narrow down our data to be from 2006 through 2016, unless, from the results, it looks like we will need more data to come to a conclusion..\n",
    "\n",
    "First, some definitions and functions that I'll need to get and clean the dataframes from the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_years = [x for x in range(2006,2017)] \n",
    "folder_names = []\n",
    "\n",
    "# making a list of all the folders\n",
    "for year in target_years:\n",
    "    folder_names.append('Hate Crime Statistics '+ str(year) + ' Tables/')\n",
    "\n",
    "path = \"/Users/gemma/Documents/data science/Hate Crime FBI Data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the file names i'll be working with\n",
    "file_names = ['table4.xls','table11.xls', 'table13.xlsx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary of the US States and their abbreviations was provided by [github user rogerallen](https://gist.github.com/rogerallen/1583593)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to use this also\n",
    "\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK','Arizona': 'AZ', 'Arkansas': 'AR',\n",
    "    'California': 'CA', 'Colorado': 'CO','Connecticut': 'CT','Delaware': 'DE',\n",
    "    'District Of Columbia': 'DC','District of Columbia': 'DC', 'Florida': 'FL', 'Georgia': 'GA','Hawaii': 'HI',\n",
    "    'Idaho': 'ID', 'Illinois': 'IL','Indiana': 'IN','Iowa': 'IA','Kansas': 'KS',\n",
    "    'Kentucky': 'KY','Louisiana': 'LA','Maine': 'ME','Maryland': 'MD',\n",
    "    'Massachusetts': 'MA','Michigan': 'MI','Minnesota': 'MN','Mississippi': 'MS',\n",
    "    'Missouri': 'MO','Montana': 'MT', 'Nebraska': 'NE','Nevada': 'NV',\n",
    "    'New Hampshire': 'NH','New Jersey': 'NJ','New Mexico': 'NM','New York': 'NY',\n",
    "    'North Carolina': 'NC','North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR', 'Outlying Areas': 'Other', 'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN','Texas': 'TX','Utah': 'UT','Vermont': 'VT', 'Virginia': 'VA',\n",
    "    'Washington': 'WA','West Virginia': 'WV','Wisconsin': 'WI','Wyoming': 'WY',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename duplicate columns\n",
    "class renamer():\n",
    "    def __init__(self):\n",
    "        self.d = dict()\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        if x not in self.d:\n",
    "            self.d[x] = 0\n",
    "            return x\n",
    "        else:\n",
    "            self.d[x] += 1\n",
    "            return \"%s_%d\" % (x, self.d[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, Table 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to rename the columns to clearer /consistent names\n",
    "table_11_dict = {'index': 'State_name',\n",
    "                 'Crimes\\nagainst\\nsociety1Unnamed: 14_level_1' : 'Crimes c society',\n",
    "                 'Crimes\\nagainst\\nsociety3Unnamed: 15_level_1': 'Crimes c society',\n",
    "                 'Crimes against personsOther1': 'Other Crimes c persons',\n",
    "                 'Crimes against personsOther3': 'Other Crimes c persons',\n",
    "                 'Crimes against personsForcible\\nrape': 'Rape (legacy)',\n",
    "                 'Crimes against personsRape\\n(legacy\\ndefinition)2': 'Rape (legacy)',\n",
    "                 'Crimes against personsRape\\n(legacy\\ndefinition2)': 'Rape (legacy)',\n",
    "                 'Crimes against personsRape\\n(revised\\ndefinition)1': 'Rape (revised)',\n",
    "                 'Crimes against personsRape\\n(revised\\ndefinition1)':'Rape (revised)',\n",
    "                 'Crimes against propertyOther1': 'Other Crimes c property',\n",
    "                 'Crimes against propertyOther3': 'Other Crimes c property',\n",
    "                 'Total\\noffensesUnnamed: 0_level_1': 'Total offenses',\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables_by_year(this_path, header_text, footer_text, year_number):\n",
    "\n",
    "    # read in the file first to get some info out of it\n",
    "    onbir = pd.read_excel(this_path)\n",
    "\n",
    "    # find the start row using the passed in header_text\n",
    "    found = False\n",
    "    for col in range(onbir.shape[1]):\n",
    "        for row in range(onbir.shape[0]):\n",
    "                if onbir.iat[row,col] == header_text and found == False:\n",
    "                    row_start = row +1\n",
    "                    found = True\n",
    "        # find the last row of content\n",
    "                if (onbir.iat[row,0] ==  footer_text):\n",
    "                    last_row = row+1\n",
    "                    break\n",
    "\n",
    "    # rereading the file, with the header\n",
    "    onbir = pd.read_excel(this_path, header=[row_start-1, row_start], \n",
    "                          skipfooter=(onbir.shape[0]-last_row))\n",
    "    \n",
    "    \n",
    "    # right now it has multilvel columns. flattening them to 1 column and keeping the names\n",
    "    colnames = onbir.columns\n",
    "    ind = pd.Index([e[0] + e[1] for e in colnames.tolist()])\n",
    "    onbir.columns = ind\n",
    "    \n",
    "    # moving the index over\n",
    "    onbir.reset_index(inplace=True)\n",
    "    \n",
    "    #fixing the names\n",
    "    onbir.rename(index=str, columns=table_11_dict, inplace=True)\n",
    "    \n",
    "    # add column for the year\n",
    "    onbir['Year'] = target_years[year_number]\n",
    "    \n",
    "    #adding state abbrev\n",
    "    onbir['State'] = onbir['State_name'].map(us_state_abbrev)\n",
    "    \n",
    "    return onbir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to put all of the table 11s into one dataframe\n",
    "\n",
    "def combine_tables(list_of_paths, header_text, footer_text):\n",
    "    \n",
    "    df_dict = {}\n",
    "        \n",
    "    for i, name in enumerate(list_of_paths):\n",
    "        df_dict[name] = tables_by_year(name, header_text,footer_text, i)\n",
    "        \n",
    "    table_11 = pd.concat(df_dict.values(), axis=0, ignore_index=True, sort=True)\n",
    "    \n",
    "    return table_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after reviewing the files i found these delimited the header and footers\n",
    "\n",
    "header_text = 'Intimidation'\n",
    "footer_text = 'Wyoming'\n",
    "\n",
    "list_of_paths_11 = [ str(path+folder+file_names[1]) for folder in folder_names]\n",
    "\n",
    "crimes_by_state = combine_tables(list_of_paths_11, header_text, footer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crimes against personsAggravated\n",
       "assault</th>\n",
       "      <th>Crimes against personsIntimidation</th>\n",
       "      <th>Crimes against personsMurder and\n",
       "nonnegligent\n",
       "manslaughter</th>\n",
       "      <th>Crimes against personsSimple\n",
       "assault</th>\n",
       "      <th>Crimes against propertyArson</th>\n",
       "      <th>Crimes against propertyBurglary</th>\n",
       "      <th>Crimes against propertyDestruction/\n",
       "damage/\n",
       "vandalism</th>\n",
       "      <th>Crimes against propertyLarceny-\n",
       "theft</th>\n",
       "      <th>Crimes against propertyMotor\n",
       "vehicle\n",
       "theft</th>\n",
       "      <th>Crimes against propertyRobbery</th>\n",
       "      <th>Crimes c society</th>\n",
       "      <th>Other Crimes c persons</th>\n",
       "      <th>Other Crimes c property</th>\n",
       "      <th>Rape (legacy)</th>\n",
       "      <th>Rape (revised)</th>\n",
       "      <th>State</th>\n",
       "      <th>State_name</th>\n",
       "      <th>Total offenses</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1178</td>\n",
       "      <td>2508</td>\n",
       "      <td>3</td>\n",
       "      <td>1737</td>\n",
       "      <td>41</td>\n",
       "      <td>155</td>\n",
       "      <td>2911</td>\n",
       "      <td>261</td>\n",
       "      <td>25</td>\n",
       "      <td>142</td>\n",
       "      <td>38</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Total</td>\n",
       "      <td>9080</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>215</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>133</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Crimes against personsAggravated\\nassault  \\\n",
       "0                                       1178   \n",
       "1                                          0   \n",
       "2                                          3   \n",
       "3                                         23   \n",
       "4                                         16   \n",
       "\n",
       "   Crimes against personsIntimidation  \\\n",
       "0                                2508   \n",
       "1                                   1   \n",
       "2                                   2   \n",
       "3                                  95   \n",
       "4                                  27   \n",
       "\n",
       "   Crimes against personsMurder and\\nnonnegligent\\nmanslaughter  \\\n",
       "0                                                  3              \n",
       "1                                                  0              \n",
       "2                                                  0              \n",
       "3                                                  0              \n",
       "4                                                  0              \n",
       "\n",
       "   Crimes against personsSimple\\nassault  Crimes against propertyArson  \\\n",
       "0                                   1737                            41   \n",
       "1                                      0                             0   \n",
       "2                                      5                             0   \n",
       "3                                     40                             0   \n",
       "4                                     36                             0   \n",
       "\n",
       "   Crimes against propertyBurglary  \\\n",
       "0                              155   \n",
       "1                                0   \n",
       "2                                0   \n",
       "3                                2   \n",
       "4                                8   \n",
       "\n",
       "   Crimes against propertyDestruction/\\ndamage/\\nvandalism  \\\n",
       "0                                               2911         \n",
       "1                                                  0         \n",
       "2                                                  1         \n",
       "3                                                 54         \n",
       "4                                                 16         \n",
       "\n",
       "   Crimes against propertyLarceny-\\ntheft  \\\n",
       "0                                     261   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                      23   \n",
       "\n",
       "   Crimes against propertyMotor\\nvehicle\\ntheft  \\\n",
       "0                                            25   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             1   \n",
       "4                                             0   \n",
       "\n",
       "   Crimes against propertyRobbery  Crimes c society  Other Crimes c persons  \\\n",
       "0                             142                38                      17   \n",
       "1                               0                 0                       0   \n",
       "2                               0                 0                       0   \n",
       "3                               0                 0                       0   \n",
       "4                               1                 0                       1   \n",
       "\n",
       "   Other Crimes c property  Rape (legacy)  Rape (revised) State State_name  \\\n",
       "0                       58            6.0             NaN   NaN      Total   \n",
       "1                        0            0.0             NaN    AL    Alabama   \n",
       "2                        0            0.0             NaN    AK     Alaska   \n",
       "3                        0            0.0             NaN    AZ    Arizona   \n",
       "4                        4            1.0             NaN    AR   Arkansas   \n",
       "\n",
       "   Total offenses  Year  \n",
       "0            9080  2006  \n",
       "1               1  2006  \n",
       "2              11  2006  \n",
       "3             215  2006  \n",
       "4             133  2006  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes_by_state.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Table 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table_13s(this_path, number):\n",
    "       \n",
    "    # first time, to find where the header ends\n",
    "    full_table = pd.read_excel(this_path, index_col=0)\n",
    "    \n",
    "    # then we're going to find which row Religion is in, bc it's one category\n",
    "    # of bias that is in all of the excel files\n",
    "    \n",
    "    found = False\n",
    "    for col in range(full_table.shape[1]):\n",
    "        for row in range(full_table.shape[0]):\n",
    "            if full_table.iat[row,col] == \"Religion\" and found == False:\n",
    "                row_start = row + 1\n",
    "                found = True\n",
    "    \n",
    "    if found == False:\n",
    "        print(\"honey you have a storm coming\")\n",
    "        \n",
    "    # now we're legit reading it in, with the state as the index\n",
    "    full_table = pd.read_excel(this_path, header=row_start) #index_col=0)\n",
    "\n",
    "    # the size of the footer is diff each table, but all of the values are Na, so we'll \n",
    "    # get rid of the footer through dropping rows that have only Na values\n",
    "    full_table.dropna(axis=0, how=\"all\", inplace=True)\n",
    "    \n",
    "    # renaming columns that are not consistently named across all files, or just bc\n",
    "    full_table.rename(index=str, \n",
    "                      columns={ 'Agency Type': 'Agency type', \n",
    "                               'Gender\\nIdentity':'Gender Identity',\n",
    "                               'Race/\\nEthnicity/\\nAncestry': 'REA'},\n",
    "                      inplace=True)\n",
    "\n",
    "    # there's one more inconsistency, it has to do with changes in how the \n",
    "    # biases were classified - they used to split up race & ethnicity, \n",
    "    # then starting from 2015 they lumped together w/ ancestry\n",
    "    \n",
    "    if 'Race' in full_table.columns.values:\n",
    "        full_table['REA'] = (full_table['Race'] + full_table['Ethnicity'])  \n",
    "    \n",
    "    # filling in the missing data in these 3 columns based on looking at the excel file\n",
    "    full_table['State'] = pd.Series(full_table.State).fillna(method=\"ffill\")\n",
    "    full_table['Agency type'] = pd.Series(full_table['Agency type']).fillna(method=\"ffill\")\n",
    "    full_table['Agency name'] = full_table['Agency name'].fillna(\"Total\")\n",
    "    \n",
    "    # adding the year for organization when the dfs are all merged\n",
    "    full_table['Year'] = target_years[number] # needs 2b same as # folder_names & target_years\n",
    "    \n",
    "    return full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to put all of the table 13s into one dataframe\n",
    "\n",
    "def combine_table13s(list_of_paths):\n",
    "    \n",
    "    df_dict = {}\n",
    "        \n",
    "    for i, name in enumerate(list_of_paths):\n",
    "        df_dict[name] = make_table_13s(name, i)\n",
    "        \n",
    "    table_13 = pd.concat(df_dict.values(), axis=0, ignore_index=True, sort=True)\n",
    "    \n",
    "    # drop cols i don't plan on needing \n",
    "    table_13.drop(['1st\\nquarter', '2nd\\nquarter', '3rd\\nquarter', '4th\\nquarter', \n",
    "                  'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15','Unnamed: 16', \n",
    "                   'Unnamed: 17', 'Unnamed: 3'], axis=1, inplace=True)\n",
    "    \n",
    "    # reorder the cols for convenience\n",
    "    table_13 = table_13[['Year','State','Agency type','Agency name',\n",
    "                         'REA', \n",
    "                         'Religion', 'Disability', 'Gender','Gender Identity',\n",
    "                         'Sexual\\norientation','Race','Ethnicity','Population']]\n",
    "    \n",
    "    # fix capitalization w helper function\n",
    "    for col in ['State', 'Agency type', 'Agency name']:\n",
    "        table_13[col] = table_13[col].apply(str.title)\n",
    "        \n",
    "    table_13.rename(index=str,columns={'State': 'State_name', \n",
    "                                       'Sexual\\norientation': 'Sexual orientation'}, inplace=True)\n",
    "       \n",
    "    # drop anything that isn't a state - my above method of removing the footer didnt work \n",
    "    return table_13.loc[table_13['State_name'].isin(us_state_abbrev.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_paths = [ str(path+folder+file_names[2]) for folder in folder_names]\n",
    "\n",
    "bias_by_state = combine_table13s(list_of_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping redundant columns or ones that I won't use\n",
    "partial_bbs = bias_by_state.drop(['Race', 'Ethnicity','Population'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State_name</th>\n",
       "      <th>Agency type</th>\n",
       "      <th>Agency name</th>\n",
       "      <th>REA</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Disability</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Gender Identity</th>\n",
       "      <th>Sexual orientation</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Cities</td>\n",
       "      <td>Total</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Cities</td>\n",
       "      <td>Atmore</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Cities</td>\n",
       "      <td>Total</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year State_name Agency type Agency name  REA Religion  Disability Gender  \\\n",
       "0  2006    Alabama       Total       Total  1.0        0         0.0    NaN   \n",
       "1  2006    Alabama      Cities       Total  1.0        0         0.0    NaN   \n",
       "2  2006    Alabama      Cities      Atmore  1.0        0         0.0    NaN   \n",
       "3  2006     Alaska       Total       Total  4.0        0         0.0    NaN   \n",
       "4  2006     Alaska      Cities       Total  4.0        0         0.0    NaN   \n",
       "\n",
       "   Gender Identity  Sexual orientation State  \n",
       "0              NaN                 0.0    AL  \n",
       "1              NaN                 0.0    AL  \n",
       "2              NaN                 0.0    AL  \n",
       "3              NaN                 2.0    AK  \n",
       "4              NaN                 2.0    AK  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_bbs['State'] = partial_bbs['State_name'].map(us_state_abbrev)\n",
    "partial_bbs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the tables. Since we have data that applies broadly (state level) and data by city, I'll make two separate tables that we can use to analyze at two different scopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making two separate tables so as to not duplicate the info\n",
    "\n",
    "state_totals = partial_bbs.loc[(partial_bbs['Agency name'] == 'Total') & (partial_bbs['Agency type'] == 'Total')]\n",
    "state_totals = state_totals[['Year','State', 'REA', 'Religion',\n",
    "       'Disability', 'Gender', 'Gender Identity', 'Sexual orientation']]\n",
    "\n",
    "by_city_only = partial_bbs.loc[(partial_bbs['Agency name'] != 'Total') & (partial_bbs['Agency type'] != 'Total')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_city_only = pd.merge(by_city_only.drop(['Agency type'],1), hatemaps, how=\"outer\",  \n",
    "                        right_on=['Year','State','City'], \n",
    "         left_on=['Year','State', 'Agency name']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by_city_only.rename(index=str, columns={'Race / Ethnicity / Ancestry':'REA'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below when I was trying to work with this dataframe, I found a ' ' in one of the columns was preventing the model from running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REA {<class 'float'>}\n",
      "Religion {<class 'float'>}\n",
      "Disability {<class 'float'>}\n",
      "Gender {<class 'str'>, <class 'int'>, <class 'float'>}\n",
      "Gender Identity {<class 'float'>}\n",
      "Sexual orientation {<class 'float'>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 4, ' ', 2, 3.0, 5.0], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in ['REA', 'Religion','Disability', 'Gender', 'Gender Identity', \n",
    "            'Sexual orientation']:\n",
    "    print(col, set([type(x) for x in by_city_only[col]]))\n",
    "    \n",
    "by_city_only['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State_name</th>\n",
       "      <th>Agency name</th>\n",
       "      <th>REA</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Disability</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Gender Identity</th>\n",
       "      <th>Sexual orientation</th>\n",
       "      <th>State</th>\n",
       "      <th>Group Name</th>\n",
       "      <th>City</th>\n",
       "      <th>Hate Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16555</th>\n",
       "      <td>2013</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>Reno</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year State_name Agency name  REA  Religion  Disability Gender  \\\n",
       "16555  2013     Nevada        Reno  2.0       1.0         0.0          \n",
       "\n",
       "       Gender Identity  Sexual orientation State Group Name City Hate Type  \n",
       "16555              0.0                 1.0    NV          0    0         0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_city_only[by_city_only['Gender'] == ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_city_only.iloc[16555, 6] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export them to csv to use in the rest of the notebooks\n",
    "\n",
    "#hatemaps.to_csv('/Users/gemma/Documents/data science/fc-hatemaps.csv')\n",
    "#crimes_by_state.to_csv('/Users/gemma/Documents/data science/fc-crimes_by_state.csv')\n",
    "#state_totals.to_csv('/Users/gemma/Documents/data science/fc-hate-state_totals.csv')\n",
    "#by_city_only.to_csv('/Users/gemma/Documents/data science/fc-hate-by_city.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partial_bbs.to_csv('/Users/gemma/Documents/data science/fc-partial_bias_byst.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
