{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title \n",
    "## 4. Modeling\n",
    "\n",
    "### Import statements and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatemaps = pd.read_csv('/Users/gemma/Documents/data science/fc-hatemaps.csv')\n",
    "crimes_by_state = pd.read_csv('/Users/gemma/Documents/data science/fc-crimes_by_state.csv')\n",
    "state_totals = pd.read_csv('/Users/gemma/Documents/data science/fc-hate-state_totals.csv')\n",
    "by_city_only = pd.read_csv('/Users/gemma/Documents/data science/fc-hate-by_city.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "First, some ideas of features that I had. Later, I'll use some unsupervised methods.\n",
    "\n",
    "* Number of unique cities per state with at least 1 reported hate crime\n",
    "* Max count of hate groups in any 1 city in each state\n",
    "* Number of unique cities per state with at least 1 hate group\n",
    "* Binary indicators of 5 largest hate groups presence in each city / state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique cities per state with at least 1 reported hate crime\n",
    "\n",
    "state_totals = pd.merge(state_totals, \n",
    "                        by_city_only.groupby(['Year','State'])['Agency name'].nunique().reset_index().rename(index=str,\n",
    "                            columns={'Agency name': 'Number of cities with 1+ hate crime'}), \n",
    "                        on=['Year','State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max count of hate groups in 1 city in each state\n",
    "\n",
    "state_totals = pd.merge(state_totals, hatemaps.groupby(['Year','State',\n",
    "                  'City'])['Group Name'].count().groupby(['Year',\n",
    "                 'State']).max().reset_index().rename(index=str,columns={'Group Name': \n",
    "                    'Largest num of hate groups in any 1 city'}),\n",
    "                        on=['Year','State'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of unique cities with 1 or more hate groups in each state per year\n",
    "\n",
    "state_totals = pd.merge(state_totals, \n",
    "                        hatemaps.groupby(['Year',\n",
    "                            'State'])['City'].nunique().reset_index().rename(index=str,\n",
    "                            columns={'City': 'Number of cities with 1+ hate groups'}), \n",
    "                        on=['Year','State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the cumulatively largest 5 hate groups (by count) in each category, \n",
    "# binary indicators of whether or not they exist in each state\n",
    "\n",
    "# first get the names of the hate groups\n",
    "largest_five = []\n",
    "\n",
    "for htype in hatemaps['Hate Type'].unique():\n",
    "\n",
    "    templist = hatemaps[hatemaps['Hate Type'] == htype].groupby(['Group Name'])['Group Name'].count().sort_values(ascending=False).head(5).index.tolist()\n",
    "\n",
    "    for gr_name in templist:\n",
    "        # add it to the list of largest five\n",
    "        largest_five.append(gr_name)\n",
    "        # also add a column to the hatemaps\n",
    "        hatemaps[gr_name] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then add the names to the dataframe\n",
    "\n",
    "for i, name in enumerate(hatemaps['Group Name'].tolist()):\n",
    "    if name in largest_five:\n",
    "        hatemaps.loc[i, name] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add them as features to the states table\n",
    "\n",
    "state_totals = pd.merge(state_totals, \n",
    "                        hatemaps.groupby(['Year','State'])[largest_five].sum().reset_index(), \n",
    "                        on=['Year','State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add them as features to the city table as well\n",
    "\n",
    "by_city_only = pd.merge(by_city_only, hatemaps, how=\"outer\",  \n",
    "                        right_on=['Year','State','City'], \n",
    "         left_on=['Year','State', 'Agency name']).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering with unsupervised learning\n",
    "\n",
    "* NLP - topic extraction\n",
    "* Autoencoders?? (neural networks)\n",
    "* clusters with mean shift\n",
    "\n",
    "Using NLP I'll analyze the names of the hategroups and design features that will then be added to the tables above.\n",
    "\n",
    "* keyword extraction\n",
    "* topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the hate group names\n",
    "\n",
    "hgnames = hatemaps['Group Name'].tolist()\n",
    "\n",
    "newlist = []\n",
    "\n",
    "for word in hgnames:\n",
    "    newlist.append(word.replace('the',''))\n",
    "\n",
    "hgnames_string = \". \".join(hgnames)\n",
    "newlist_string = \". \".join(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "# parse the names\n",
    "hgp = nlp(newlist_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the text into sentences and storing them as a list of strings.\n",
    "sentences=[]\n",
    "for span in hgp.sents:\n",
    "    # go from the start to the end of each span, returning each token in the sentence\n",
    "    # combine each token using join()\n",
    "    sent = ''.join(hgp[i].string for i in range(span.start, span.end)).strip()\n",
    "    sentences.append(sent)\n",
    "\n",
    "# Creating the tf-idf matrix.\n",
    "counter = TfidfVectorizer(lowercase=False, \n",
    "                          stop_words='english',\n",
    "                          ngram_range=(1, 1), \n",
    "                          analyzer=u'word', \n",
    "                          max_df=.5, \n",
    "                          min_df=1,\n",
    "                          max_features=None, \n",
    "                          vocabulary=None, \n",
    "                          binary=False)\n",
    "\n",
    "#Applying the vectorizer\n",
    "data_counts=counter.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['christian', 'american', 'knights', 'ku', 'klu', 'klan', 'church', 'national', 'knights', 'ku', 'klu', 'klan', 'confederate', 'white', 'knights', 'ku', 'klu', 'klan', 'east coast', 'knights', 'true invisible', 'empire', 'georgia knight', 'riders', 'ku']\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english') + list(string.punctuation) + [\"''\", \"``\" , \"--\", \"n't\", \"'ve\", \"'s\"]\n",
    "\n",
    "\n",
    "sentence_stream = [[i.lower() for i in nltk.word_tokenize(sent) if i.lower() not in stop]  for sent in sentences]\n",
    "bigram = Phrases(sentence_stream, min_count=1, threshold=3, delimiter=b' ')\n",
    "bigram_phraser = Phraser(bigram)\n",
    "tokens_ = bigram_phraser[sentence_stream]\n",
    "\n",
    "bigrams_t = tokens_\n",
    "\n",
    "bigrams_o = [i for j in bigrams_t for i in j]\n",
    "print(bigrams_o[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words and punctuation, then getting a list of all unique words in the text\n",
    "hgp_filt_2 = [word for word in bigrams_o if word not in stop]\n",
    "words2=set(hgp_filt_2)\n",
    "\n",
    "#Creating a grid indicating whether words are within 4 places of the target word\n",
    "adjacency2=pd.DataFrame(columns=words2,index=words2,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(bigrams_o):\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    if any([word == item for item in hgp_filt_2]):\n",
    "        # Making sure to stop at the end of the string, even if there are less than \n",
    "        # four words left after the target.\n",
    "        end=max(0,len(bigrams_o)-(len(bigrams_o)-(i+6)))\n",
    "        # The potential neighbors.\n",
    "        nextwords=bigrams_o[i+1:end]\n",
    "        # Filtering the neighbors to select only those in the word list\n",
    "        inset=[x in hgp_filt_2 for x in nextwords]\n",
    "        neighbors=[nextwords[i] for i in range(len(nextwords)) if inset[i]]\n",
    "        # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "        if neighbors:\n",
    "            adjacency2.loc[word,neighbors]=adjacency2.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.03218013173297323, 'knights'), (0.031171350170183174, 'ku'), (0.03097284375580873, 'klan'), (0.03021227245517635, 'klu'), (0.025756638636265785, 'national')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Running TextRank\n",
    "nx_words2 = nx.from_numpy_matrix(adjacency2.as_matrix())\n",
    "ranks2=nx.pagerank(nx_words2, alpha=.85, tol=.00000001)\n",
    "\n",
    "# Identifying the five most highly ranked keywords\n",
    "ranked2 = sorted(((ranks2[i],s) for i,s in enumerate(words2)),\n",
    "                reverse=True)\n",
    "print(ranked2[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['christian', 'american', 'knights', 'ku', 'klu', 'klan', 'church', 'national', 'knights', 'ku', 'klu', 'klan', 'confederate white', 'knights', 'ku', 'klu', 'klan', 'east coast', 'knights', 'true invisible empire', 'georgia knight riders', 'ku', 'klu', 'klan', 'great', 'lakes', 'knights', 'ku', 'klu', 'klan', 'international keystone', 'knights', 'ku', 'klu', 'klan', 'knights', 'ku', 'klu', 'klan', 'knights', 'white disciples', 'ku', 'klos', 'knights', 'ku', 'klu', 'klan', 'loyal white', 'knights', 'ku']\n"
     ]
    }
   ],
   "source": [
    "trigram = Phrases(tokens_, min_count=1, threshold=2, delimiter=b' ')\n",
    "trigram_phraser = Phraser(trigram)\n",
    "tokens__ = trigram_phraser[tokens_]\n",
    "\n",
    "all_words = [i for j in tokens__ for i in j]\n",
    "print(all_words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words and punctuation, then getting a list of all unique words in the text\n",
    "gatsby_filt_2 = [word for word in all_words if word not in stop]\n",
    "words2=set(gatsby_filt_2)\n",
    "\n",
    "#Creating a grid indicating whether words are within 4 places of the target word\n",
    "adjacency2=pd.DataFrame(columns=words2,index=words2,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(all_words):\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    if any([word == item for item in gatsby_filt_2]):\n",
    "        # Making sure to stop at the end of the string, even if there are less than \n",
    "        # four words left after the target.\n",
    "        end=max(0,len(all_words)-(len(all_words)-(i+6)))\n",
    "        # The potential neighbors.\n",
    "        nextwords=all_words[i+1:end]\n",
    "        # Filtering the neighbors to select only those in the word list\n",
    "        inset=[x in gatsby_filt_2 for x in nextwords]\n",
    "        neighbors=[nextwords[i] for i in range(len(nextwords)) if inset[i]]\n",
    "        # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "        if neighbors:\n",
    "            adjacency2.loc[word,neighbors]=adjacency2.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.03178269853982189, 'knights'), (0.0312698261154431, 'national'), (0.03077380496419143, 'ku'), (0.030682882672809095, 'klan'), (0.0298041768475479, 'klu')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Running TextRank\n",
    "nx_words2 = nx.from_numpy_matrix(adjacency2.as_matrix())\n",
    "ranks2=nx.pagerank(nx_words2, alpha=.85, tol=.00000001)\n",
    "\n",
    "# Identifying the five most highly ranked keywords\n",
    "ranked2 = sorted(((ranks2[i],s) for i,s in enumerate(words2)),\n",
    "                reverse=True)\n",
    "print(ranked2[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting keywords with both bigram and trigram resulted in very similar results, perhaps unsurprisingly, considering the sizes of the hate groups from the data analysis section. They show that the most common key words are variations of \"ku klux klan\" for the most part, and also \"white\", \"american\", and \"state\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the vectors from the keywords back into the hatemaps dataframe\n",
    "\n",
    "hatemaps['vector'] = 0\n",
    "\n",
    "for v, k in ranked2:\n",
    "    for i in hatemaps[hatemaps['Group Name'].str.contains(k)].index:\n",
    "        #print(hatemaps['Group Name'].str.contains(k).index)\n",
    "        hatemaps.loc[i, 'vector'] += v\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_city_only.rename(index=str,columns={'Agency name': 'City'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a vector for the city if there is data for it\n",
    "vector_city = hatemaps.groupby(['City','State','Year'])['vector'].sum().reset_index()\n",
    "\n",
    "by_city_only = pd.merge(by_city_only,vector_city, on=['Year','State','City'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vector for the state, just in case there is no city vector\n",
    "vector_state = hatemaps.groupby(['State','Year'])['vector'].sum().reset_index()\n",
    "\n",
    "by_city_only = pd.merge(by_city_only,vector_state, on=['Year','State'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>REA</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Disability</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Gender Identity</th>\n",
       "      <th>Sexual orientation</th>\n",
       "      <th>Total offenses</th>\n",
       "      <th>...</th>\n",
       "      <th>micetrap distribution</th>\n",
       "      <th>desastrious records</th>\n",
       "      <th>tightrope</th>\n",
       "      <th>tradition in action</th>\n",
       "      <th>slaves of the immaculate heart of mary</th>\n",
       "      <th>catholic counterpoint</th>\n",
       "      <th>culture wars/fidelity press</th>\n",
       "      <th>omni christian book club</th>\n",
       "      <th>City_vector</th>\n",
       "      <th>State_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>AL</td>\n",
       "      <td>Atmore</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.588282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>AK</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Apache Junction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Bullhead City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year State             City  REA  Religion  Disability  Gender  \\\n",
       "0  2006    AL           Atmore  1.0       0.0         0.0     0.0   \n",
       "1  2006    AK        Anchorage  4.0       0.0         0.0     0.0   \n",
       "2  2006    AZ  Apache Junction  1.0       0.0         0.0     0.0   \n",
       "3  2006    AZ    Bullhead City  1.0       0.0         0.0     0.0   \n",
       "4  2006    AZ         Chandler  7.0       0.0         0.0     0.0   \n",
       "\n",
       "   Gender Identity  Sexual orientation  Total offenses      ...       \\\n",
       "0              0.0                 0.0             1.0      ...        \n",
       "1              0.0                 2.0            11.0      ...        \n",
       "2              0.0                 0.0           215.0      ...        \n",
       "3              0.0                 0.0           215.0      ...        \n",
       "4              0.0                 0.0           215.0      ...        \n",
       "\n",
       "   micetrap distribution  desastrious records  tightrope  tradition in action  \\\n",
       "0                    0.0                  0.0        0.0                  0.0   \n",
       "1                    0.0                  0.0        0.0                  0.0   \n",
       "2                    0.0                  0.0        0.0                  0.0   \n",
       "3                    0.0                  0.0        0.0                  0.0   \n",
       "4                    0.0                  0.0        0.0                  0.0   \n",
       "\n",
       "   slaves of the immaculate heart of mary  catholic counterpoint  \\\n",
       "0                                     0.0                    0.0   \n",
       "1                                     0.0                    0.0   \n",
       "2                                     0.0                    0.0   \n",
       "3                                     0.0                    0.0   \n",
       "4                                     0.0                    0.0   \n",
       "\n",
       "   culture wars/fidelity press  omni christian book club  City_vector  \\\n",
       "0                          0.0                       0.0          NaN   \n",
       "1                          0.0                       0.0          NaN   \n",
       "2                          0.0                       0.0          NaN   \n",
       "3                          0.0                       0.0          NaN   \n",
       "4                          0.0                       0.0          NaN   \n",
       "\n",
       "   State_vector  \n",
       "0      0.588282  \n",
       "1      0.066278  \n",
       "2      0.182106  \n",
       "3      0.182106  \n",
       "4      0.182106  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_city_only.rename(index=str,columns={'vector_x': 'City_vector',\n",
    "                                      'vector_y': 'State_vector'}, inplace=True)\n",
    "by_city_only.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering \n",
    "\n",
    "I am going to use mean shift because it won't assign all points to a cluster unless it is close enough, and because the algorithm doesn't assume that each cluster has to be the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, splitting the data to x and y, then normalizing it\n",
    "\n",
    "outcome_vs = ['REA','Religion', 'Disability','Gender','Gender Identity', 'Sexual orientation']\n",
    "   \n",
    "X = by_city_only.drop(['REA','Religion','Group Name', 'City_y', 'Hate Type',\n",
    "                       'Disability','Gender','Gender Identity',  'City_x',\n",
    "                       'Sexual orientation', 'State', 'City',], 1).fillna(0)\n",
    "Y = by_city_only[outcome_vs].fillna(0)\n",
    "\n",
    "X_train_mo, X_test_mo, y_train_mo, y_test_mo = train_test_split(\n",
    "    X, Y, test_size=0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then scaling the data \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(X_train_mo)\n",
    "x_test_scaled = scaler.fit_transform(X_test_mo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimated clusters: 124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "# Here we set the bandwidth. This function automatically derives a bandwidth\n",
    "# number based on an inspection of the distances among points in the data.\n",
    "bandwidth = estimate_bandwidth(x_train_scaled, quantile=0.2, n_samples=500)\n",
    "\n",
    "# Declare and fit the model.\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "ms.fit(x_train_scaled)\n",
    "\n",
    "# Extract cluster assignments for each data point.\n",
    "labels = ms.labels_\n",
    "\n",
    "# Coordinates of the cluster centers.\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# Count our clusters.\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "\n",
    "print(\"Number of estimated clusters: {}\".format(n_clusters_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_s = pd.Series(ms.labels_.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mo.insert(loc=0, column='meanshift', value=clusters_s.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#x_test_scaled = scaler.fit_transform(X_test_mo)\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = estimate_bandwidth(x_train_scaled, quantile=0.2, n_samples=500)\n",
    "\n",
    "# Declare and fit the model.\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "ms.fit(X_scaled)\n",
    "\n",
    "# Extract cluster assignments for each data point.\n",
    "labels = ms.labels_\n",
    "\n",
    "clusters_X = pd.Series(ms.labels_.tolist())\n",
    "\n",
    "X.insert(loc=0, column='meanshift', value=clusters_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mo, X_test_mo, y_train_mo, y_test_mo = train_test_split(\n",
    "    X, Y, test_size=0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, some feature selection with KBest and feature importance...\n",
    "\n",
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Create an SelectKBest object to select features with k best ANOVA F-Values\n",
    "#fvalue_selector = SelectKBest(f_classif, k=25)\n",
    "\n",
    "#coltitles = by_city_only.columns.values\n",
    "\n",
    "# Apply the SelectKBest object to the features and target\n",
    "#X_kbest = fvalue_selector.fit_transform(X, Y)\n",
    "\n",
    "#print('Original number of features:', X.shape[1])\n",
    "#print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning with state data\n",
    "\n",
    "## Random forest\n",
    "\n",
    "with multi output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = ensemble.RandomForestRegressor(warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = ensemble.RandomForestRegressor(n_estimators=100, warm_start=True)\n",
    "\n",
    "rfr.fit(X_train_mo, y_train_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8284221393906167"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(X_test_mo,y_test_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.796139255144787 +/- 0.07225674158175797\n"
     ]
    }
   ],
   "source": [
    "test_score_rfr_mo = cross_val_score(rfr, X_test_mo, y_test_mo, cv=10)\n",
    "\n",
    "print('Testing score: {} +/- {}'.format(np.mean(test_score_rfr_mo),np.std(test_score_rfr_mo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rfr.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfr.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "name_of_cols = X_test_mo.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "0. feature 32 - White Nationalist (0.500292)\n",
      "1. feature 21 - Anti-Muslim (0.090374)\n",
      "2. feature 18 - Hate Type Count (0.079152)\n",
      "3. feature 25 - Holocaust Denial (0.047009)\n",
      "4. feature 103 - State_vector (0.023936)\n",
      "5. feature 22 - Black Nationalist (0.020929)\n",
      "6. feature 102 - City_vector (0.019596)\n",
      "7. feature 4 - Intimidation (0.018452)\n",
      "8. feature 2 - Total offenses (0.016116)\n",
      "9. feature 3 - Aggravated assault (0.014849)\n",
      "10. feature 31 - Radical Traditional Catholicism (0.014750)\n",
      "11. feature 13 - Larceny theft (0.014518)\n",
      "12. feature 12 - Destruction damage vandalism (0.011649)\n",
      "13. feature 6 - Simple assault (0.010337)\n",
      "14. feature 20 - Anti-LGBT (0.010006)\n"
     ]
    }
   ],
   "source": [
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range((len(X.head(15)))):\n",
    "    print(\"%d. feature %d - %s (%f)\" % (f, \n",
    "                                        indices[f], name_of_cols[int(indices[f])],\n",
    "                                        importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train_mo.iloc[:,:20].shape[1]), importances[indices[:20]],\n",
    "       color=\"r\", yerr=std[indices[:20]], align=\"center\")\n",
    "plt.xticks(range(X_train_mo.iloc[:,:20].shape[1]), name_of_cols[indices[:20]], rotation=90)\n",
    "plt.xlim([-1, X_train_mo.iloc[:,:20].shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New X with reduced number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X[name_of_cols[indices[:25]]]\n",
    "Y_reduced = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced_train, X_reduced_test, y_reduced_train, y_reduced_test = train_test_split(\n",
    "    X_reduced, Y_reduced, test_size=0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = ensemble.RandomForestRegressor(n_estimators=100, warm_start=True)\n",
    "\n",
    "rfr.fit(X_reduced_train, y_reduced_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.8189347825929911 +/- 0.07660931521402377\n"
     ]
    }
   ],
   "source": [
    "test_score_rfr_red = cross_val_score(rfr, X_reduced_test, y_reduced_test, cv=10)\n",
    "\n",
    "print('Testing score: {} +/- {}'.format(np.mean(test_score_rfr_red),np.std(test_score_rfr_red)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with multi output\n",
    "\n",
    "Using the already scaled data, above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the best # for n\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "params = {'n_neighbors':[2,3,4,5,6,7,8,9], 'weights': ['uniform', 'distance']}\n",
    "\n",
    "model = GridSearchCV(knn, params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_scaled,y_train_mo)\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
       "          weights='distance')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=4, weights='distance')\n",
    "\n",
    "knn.fit(x_train_scaled,y_train_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7565875578013151"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_test_scaled,y_test_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.727357183890404 +/- 0.08100337541316273\n"
     ]
    }
   ],
   "source": [
    "test_score_knn = cross_val_score(knn, x_test_scaled, y_test_mo, cv=10)\n",
    "\n",
    "print('Testing score: {} +/- {}'.format(np.mean(test_score_knn),np.std(test_score_knn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using the reduced set of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train_scaled_red = scaler.fit_transform(X_reduced_train)\n",
    "x_test_scaled_red = scaler.fit_transform(X_reduced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
       "          weights='distance')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train_scaled_red, y_train_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.797281894948923"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_test_scaled_red,y_test_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.7852693187771853 +/- 0.08682483673309256\n"
     ]
    }
   ],
   "source": [
    "test_score_knn_red = cross_val_score(knn, x_test_scaled_red, y_test_mo, cv=10)\n",
    "\n",
    "print('Testing score: {} +/- {}'.format(np.mean(test_score_knn_red),np.std(test_score_knn_red)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with Multi Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "           n_jobs=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "svr_mor = MultiOutputRegressor(SVR())\n",
    "\n",
    "svr_mor.fit(X_train_mo,y_train_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14128958756446816"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_mor.score(X_test_mo,y_test_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.09711045344373592 +/- 0.20082004902796377\n"
     ]
    }
   ],
   "source": [
    "test_score_svrm = cross_val_score(svr_mor, X_test_mo, y_test_mo, cv=10)\n",
    "\n",
    "print('Testing score: {} +/- {}'.format(np.mean(test_score_svrm),np.std(test_score_svrm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With reduced set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "           n_jobs=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_mor.fit(X_reduced_train,y_reduced_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.0979738829416652 +/- 0.2046514306863591\n"
     ]
    }
   ],
   "source": [
    "test_score_svrm_r = cross_val_score(svr_mor, X_reduced_test, y_reduced_test, cv=10)\n",
    "\n",
    "print('Testing score: {} +/- {}'.format(np.mean(test_score_svrm_r),np.std(test_score_svrm_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=500, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "           n_jobs=1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2}\n",
    "\n",
    "clf = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "clf_mor = MultiOutputRegressor(ensemble.GradientBoostingRegressor(**params))\n",
    "\n",
    "clf_mor.fit(X_train_mo, y_train_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6598469392322192"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mor.score(X_test_mo,y_test_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.6390171358517447 +/- 0.07172218326765195\n"
     ]
    }
   ],
   "source": [
    "test_score_clf = cross_val_score(clf_mor, X_test_mo, y_test_mo, cv=10)\n",
    "\n",
    "print('Testing score: {} +/- {}'.format(np.mean(test_score_clf),np.std(test_score_clf)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduced set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=500, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "           n_jobs=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mor.fit(X_reduced_train,y_reduced_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.657215340476313 +/- 0.07746401910267958\n"
     ]
    }
   ],
   "source": [
    "test_score_clf_r = cross_val_score(clf_mor, X_reduced_test, y_reduced_test, cv=10)\n",
    "\n",
    "print('Testing score: {} +/- {}'.format(np.mean(test_score_clf_r),np.std(test_score_clf_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_models = pd.DataFrame(index= ['full - mean','full - std','reduced - mean', 'reduced - std'])\n",
    "\n",
    "summary_models['Random forest'] = [np.mean(test_score_rfr_mo), np.std(test_score_rfr_mo),\n",
    "                           np.mean(test_score_rfr_red), np.std(test_score_rfr_red)]\n",
    "\n",
    "summary_models['KNN'] = [np.mean(test_score_knn), np.std(test_score_knn),\n",
    "                           np.mean(test_score_knn_red), np.std(test_score_knn_red)]\n",
    "\n",
    "summary_models['SVR'] = [np.mean(test_score_svrm), np.std(test_score_svrm),\n",
    "                           np.mean(test_score_svrm_r), np.std(test_score_svrm_r)]\n",
    "\n",
    "summary_models['Gradient boosting'] = [np.mean(test_score_clf), np.std(test_score_clf),\n",
    "                           np.mean(test_score_clf_r), np.std(test_score_clf_r)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random forest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVR</th>\n",
       "      <th>Gradient boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full - mean</th>\n",
       "      <td>0.796139</td>\n",
       "      <td>0.727357</td>\n",
       "      <td>0.097110</td>\n",
       "      <td>0.639017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full - std</th>\n",
       "      <td>0.072257</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>0.071722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduced - mean</th>\n",
       "      <td>0.818935</td>\n",
       "      <td>0.785269</td>\n",
       "      <td>0.097974</td>\n",
       "      <td>0.657215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduced - std</th>\n",
       "      <td>0.076609</td>\n",
       "      <td>0.086825</td>\n",
       "      <td>0.204651</td>\n",
       "      <td>0.077464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Random forest       KNN       SVR  Gradient boosting\n",
       "full - mean          0.796139  0.727357  0.097110           0.639017\n",
       "full - std           0.072257  0.081003  0.200820           0.071722\n",
       "reduced - mean       0.818935  0.785269  0.097974           0.657215\n",
       "reduced - std        0.076609  0.086825  0.204651           0.077464"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
